{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  A class will be created containing the regressor and all of its methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 The logistic regressor class and its methods\n",
    "class LogisticReg:\n",
    "    '''\n",
    "        Logitic Regression, by Wladi Arce.\n",
    "        \n",
    "        This class creates an instance of a logistic regressor, which allows to classify data\n",
    "        into 2 categories, 0 and 1.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.theta = 0.5 * np.random.randn(x_train_scaled.shape[1], 1) #Initializes randomly the weights\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        '''\n",
    "            Performs logistic regression given the matrix of parameters\n",
    "        '''\n",
    "        probability = 1/(1 + np.exp(-np.matmul(x, self.theta)))\n",
    "        return probability\n",
    "    \n",
    "    def compute_cost(self, x, y):\n",
    "        '''\n",
    "            Cost function\n",
    "        '''\n",
    "        cost = np.mean(-y*np.log(self.sigmoid(x)) - (1-y)*np.log(1-self.sigmoid(x)))\n",
    "        return cost\n",
    "    \n",
    "    def compute_gradient(self, x, y):\n",
    "        '''\n",
    "            Calculates the gradient given the expected output and the parameters\n",
    "        '''\n",
    "        gradient = np.mean(np.matmul(x.T,self.sigmoid(x)-y))\n",
    "        return gradient\n",
    "\n",
    "    def fit(self, x, y, learning_rate = 0.01, batch_size = 10, epochs = 50):\n",
    "        '''\n",
    "            Fits the regressor to the data using minibatch gradient descent as follows:\n",
    "            \n",
    "            x\n",
    "            y\n",
    "            learning_rate (default 0.01)\n",
    "            batch_size (default 10)\n",
    "            epochs (default 50)\n",
    "            \n",
    "            compute number of batches\n",
    "            for each epoch:\n",
    "                shuffle dataset\n",
    "                for i in number_of_batches:\n",
    "                    x_batch = select [batch_size] of the features dataset\n",
    "                    y_batch = select [batch_size] of the output dataset\n",
    "                    compute gradient with x_batch, y_batch\n",
    "                    apply gradient descent to update the parameters                          \n",
    "        '''\n",
    "        num_samples = x.shape[0]\n",
    "        N_iterations = int(num_samples / batch_size) * epochs\n",
    "        start = 0\n",
    "        end = 0\n",
    "        \n",
    "        for step in range(N_iterations):\n",
    "            # if new epoch, shuffle the data\n",
    "            if step % (num_samples / batch_size) == 0:\n",
    "                indexes = np.random.permutation(x.shape[0])\n",
    "                y = y[indexes]\n",
    "                x = x[indexes]\n",
    "            \n",
    "            # create a mini-batch of data to train on\n",
    "            end = start + batch_size\n",
    "            if end >= num_samples:\n",
    "                end = num_samples\n",
    "            x_batch = x[start:end, :]\n",
    "            y_batch = y[start:end]\n",
    "            start = 0 if end >= num_samples else end\n",
    "\n",
    "            # update parameters using a x_step and y_step\n",
    "            self.theta= self.theta - learning_rate * self.compute_gradient(x_batch, y_batch)\n",
    "        training_cost = self.compute_cost(x[:,:], y)\n",
    "        print('training cost: %f' %training_cost)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "            Is basically the sigmoid function, but will convert the probabilities into binary values\n",
    "        '''\n",
    "        return self.sigmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 The confusion matrix and the accuracy calculator\n",
    "\n",
    "def compute_accuracy(y_real, y_pred):\n",
    "    '''\n",
    "        Checks how many values are equal between the real data and the predicted data\n",
    "    '''\n",
    "    correct = y_real == y_pred\n",
    "    return np.sum(correct)/correct.shape[0]\n",
    "\n",
    "# This function has been taken from sklearn documentation\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# load the dataset\n",
    "data = load_breast_cancer()\n",
    "x = data.data\n",
    "y = data.target\n",
    "\n",
    "# split into training and test sets\n",
    "N_train = int(0.8 * x.shape[0])\n",
    "\n",
    "x_train = x[:N_train,:]\n",
    "y_train = np.reshape(y[:N_train], (-1,1))\n",
    "x_test = x[N_train:,:]\n",
    "y_test = np.reshape(y[N_train:], (-1,1))\n",
    "\n",
    "# scale features by removing mean and dividing by the standard deviation\n",
    "x_train_scaled = (x_train - np.average(x_train, 0))/np.std(x_train)\n",
    "x_test_scaled = (x_test - np.average(x_test, 0))/np.std(x_test)\n",
    "\n",
    "# Add intercept terms and initialize parameters\n",
    "x_train_scaled = np.hstack((np.ones((x_train_scaled.shape[0], 1)), x_train_scaled))\n",
    "x_test_scaled = np.hstack((np.ones((x_test_scaled.shape[0], 1)), x_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training cost: 0.253194\n"
     ]
    }
   ],
   "source": [
    "# An instance of the Regression model will be created, and the fit method run with the train set\n",
    "\n",
    "classifier = LogisticReg()\n",
    "classifier.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Having the model fit, values for the test set will be predicted, and \n",
    "# then compared against the real output. The accuracy will be computed\n",
    "# and the confusion matrix will show in a very visual way its performance\n",
    "\n",
    "# PREDICTION\n",
    "y_pred = classifier.predict(x_test_scaled)\n",
    "\n",
    "# TEST SET COST\n",
    "test_cost = classifier.compute_cost(x_test_scaled,y_test)\n",
    "print('Test cost: ',test_cost)\n",
    "\n",
    "# ACCURACY\n",
    "print(\"Accuracy on test set: {:.2f}\".format(compute_accuracy(y_test,y_pred)))\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "labels = ['Benign','Malignant']\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels, title='Confusion matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
